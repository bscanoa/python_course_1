{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0e654fb5ef980a1be22848a5943c51907ea7b51e6baa892e44e63c31ac515a685",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "36cf16204b8548560b1c020c4e8fb5b57f0e4c58016f52f2d4be01e192833930"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "But soft what light through yonder window breaks\nIt is the east and Juliet is the sun\nArise fair sun and kill the envious moon\nWho is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "for line in fhand:\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{'But': 1, 'soft': 1, 'what': 1, 'light': 1, 'through': 1, 'yonder': 1, 'window': 1, 'breaks': 1, 'It': 1, 'is': 3, 'the': 3, 'east': 1, 'and': 3, 'Juliet': 1, 'sun': 2, 'Arise': 1, 'fair': 1, 'kill': 1, 'envious': 1, 'moon': 1, 'Who': 1, 'already': 1, 'sick': 1, 'pale': 1, 'with': 1, 'grief': 1}\n"
     ]
    }
   ],
   "source": [
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "\n",
    "counts = dict()\n",
    "for line in fhand:\n",
    "    words = line.decode().split()\n",
    "    for word in words:\n",
    "        counts[word] = counts.get(word, 0) + 1\n",
    "\n",
    "list_of_w = []\n",
    "bigcount = None\n",
    "for word,count in counts.items():\n",
    "    if bigcount is None or count >= bigcount:\n",
    "        bigcount = count\n",
    "        h = (word, count)\n",
    "        list_of_w.append(h) \n",
    "        \n",
    "\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<h1>The First Page</h1>\n",
      "<p>\n",
      "If you like, you can switch to the\n",
      "<a href=\"http://www.dr-chuck.com/page2.htm\">\n",
      "Second Page</a>.\n",
      "</p>\n",
      "\n",
      "This is the second page:\n",
      "<h1>The Second Page</h1>\n",
      "<p>\n",
      "If you like, you can switch back to the\n",
      "<a href=\"page1.htm\">\n",
      "First Page</a>.\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "fhand = urllib.request.urlopen(\"http://www.dr-chuck.com/page1.htm\")\n",
    "for line in fhand:\n",
    "    line = line.decode().strip()\n",
    "    print(line)\n",
    "    if re.search('href.+', line):\n",
    "        ufs = re.findall('\"(.+?)\"', line)\n",
    "     \n",
    "fhand_2 = urllib.request.urlopen(ufs[0])\n",
    "\n",
    "print('\\nThis is the second page:')\n",
    "for line_2 in fhand_2:\n",
    "    line_2 = line_2.decode().strip()\n",
    "    print(line_2)\n",
    "       "
   ]
  },
  {
   "source": [
    "### Worked example: Using urllib"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "But soft what light through yonder window breaks\nIt is the east and Juliet is the sun\nArise fair sun and kill the envious moon\nWho is already sick and pale with grief\n"
     ]
    }
   ],
   "source": [
    "import urllib.request, urllib.parse, urllib.error\n",
    "\n",
    "fhand = urllib.request.urlopen('http://data.pr4e.org/romeo.txt')\n",
    "    print(line.decode().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "b'<h1>The First Page</h1>\\n<p>\\nIf you like, you can switch to the \\n<a href=\"http://www.dr-chuck.com/page2.htm\">\\nSecond Page</a>.\\n</p>\\n'\nThe First Page\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "response = urllib.request.urlopen(\"http://www.dr-chuck.com/page1.htm\")\n",
    "html = response.read()\n",
    "print(html)\n",
    "s = BeautifulSoup(html, 'xml')\n",
    "tx = s.get_text()\n",
    "print(tx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}